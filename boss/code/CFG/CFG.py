from nltk import CFG
import itertools
import numpy as np
from collections import defaultdict
from nltk.grammar import Nonterminal
from nltk import Tree


class Grammar(CFG):
    """
    Extended context free grammar (CFG) class from the NLTK python package
    We have provided functionality to sample from the CFG. 
    We have included generation capability within the class (before it was an external function)
    Also allow sampling to return whole trees (not just the string of terminals)
    """

    def __init__(self, *args, **kwargs):
        super(Grammar, self).__init__(*args, **kwargs)
        # store some extra quantities needed later
        non_unique_nonterminals =[str(prod.lhs()) for prod in self.productions()]
        self.nonterminals = list(set(non_unique_nonterminals))
        self.terminals = list(set([str(individual) for prod in self.productions() for individual in prod.rhs()])-set(self.nonterminals))
        # collect nonterminals that are worth swapping when doing genetic operations (i.e not those with a single production that leads to a terminal)
        self.swappable_nonterminals = list(set([i for i in non_unique_nonterminals if non_unique_nonterminals.count(i) > 1]))

    def generator(self,n=1,depth=5):
        # return the first n strings generated by the CFG of a maximum depth 
        sequences=[]
        for sentence in self._generate(n=n,depth=depth ):
            sequences.append(' '.join(sentence))
        return sequences
    

    def sampler_restricted(self, n, max_length=5,cfactor=0.1,min_length=0):
        # sample n unqiue sequences from the CFG
        # such that the number of terminals is between min_length and max_length
        # cfactor controls the avg length of sampled sequence (see self.sampler)
        # setting smaller cfactor can reduce number of samples required to find n of specified size
        
        # store in a dict fr quick look up when seeing if its a unique sample
        sequences_dict = {}
        sequences = [[]]*n
        i=0    
        while i < n:
            sample = self._convergent_sampler(symbol=self.start(),cfactor=cfactor)
            # split up words, depth and num productions
            tree = sample[0] +")"
            # count number of terminals
            length = 0
            for t in self.terminals:
                length+=tree.count(t+")")
            # check satisfies depth restrictions
            if (length <= max_length) and (length >= min_length):
                # check not already in samples
                if tree not in sequences_dict:
                    sequences_dict[tree] = "true"
                    sequences[i]=tree
                    i+=1
        return sequences


    def sampler(self, n=1, convergent=True, cfactor=0.1):
        # sample n sequences from the CFG
        # convergent: avoids very long sequences (we advise setting True)
        # cfactor: the factor to downweight productions (cfactor=1 returns to naive sampling strategy)
        #          smaller cfactor provides smaller sequences (on average)
        
        # Note that a simple recursive traversal of the grammar (setting convergent=False) where we choose 
        # productions at random, often hits Python's max recursion depth as the longer a sequnce gets, the 
        # less likely it is to terminate. Therefore, we set the default sampler (setting convergent=True) to
        # downweight frequent productions when traversing the grammar.
        # see https://eli.thegreenplace.net/2010/01/28/generating-random-sentences-from-a-context-free-236grammar
        
        if convergent:
            return [''.join(self._convergent_sampler(symbol=self.start(),cfactor=cfactor)[0]) for i in range(0,n)]
        else:
            return [''.join(self._sampler(symbol=self.start())) for i in range(0,n)]
         
    
    def _sampler(self, symbol = None):
        # simple sampler where each production is sampled uniformly from all possible productions
        # Tree choses if return tree or list of terminals
        # recursive implementation

        #init the sequence 
        tree ="("+str(symbol)
        # collect possible productions from the starting symbol
        productions = self.productions(lhs = symbol)
        # sample 
        production = choice(productions)
        for sym in production.rhs():
            if isinstance(sym, str):
                # if terminal then add string to sequence
                tree = tree + " "+sym
            else:
                tree = tree + " "+self._sampler(sym) + ")"
        return tree

    
    def _convergent_sampler(self,cfactor,symbol = None, pcount=defaultdict(int)):
        # sampler that down-weights the probability of selcting the same production many times
        # ensuring that the sampled trees are not 'too' long (size to be controlled by cfactor)
        #
        # recursive implementation
        #:pcount: storage for the productions used in the current branch

        
        #init the sequence
        tree ="("+str(symbol)
        # init counter of tree depth and number of production rules
        depth, num_prod = 1 , 1
        # collect possible productions from the starting symbol
        productions = self.productions(lhs = symbol)
        # init sampling weights 
        weights = []
        # calc weights for the possible productions
        for prod in productions:
            if prod in pcount:
                # if production already occured in branch then downweight
                weights.append(cfactor ** (pcount[prod]))
            else:
                #otherwise set to be 1
                weights.append(1.0)
        #normalize weights to get probabilities
        norm=sum(weights)
        probs = [weight/norm for weight in weights]
        # sample 
        production = choice(productions,probs)
        # update counts
        pcount[production] += 1
        depths=[]
        for sym in production.rhs():
            if isinstance(sym, str):
                # if terminal then add string to sequence
                tree = tree + " "+sym
            else:
                #otherwise keep generating the sequence
                recursion = self._convergent_sampler(symbol=sym, cfactor=cfactor,pcount=pcount)
                depths.append(recursion[1])
                num_prod +=  recursion[2]
                tree = tree + " "+recursion[0] + ")"
        # count the maximum depth and update

        if len(depths)>0:
            depth=max(depths) + 1
        # update counts    
        pcount[production] -= 1
        return tree, depth, num_prod

    def _generate(self, start=None, depth=None, n=None):
        """
        see https://www.nltk.org/_modules/nltk/parse/generate.html
        Generates an iterator of all sentences from a CFG.

        :param grammar: The Grammar used to generate sentences.
        :param start: The Nonterminal from which to start generate sentences.
        :param depth: The maximal depth of the generated tree.
        :param n: The maximum number of sentences to return.
        :return: An iterator of lists of terminal tokens.
        """
        if not start:
            start = self.start()
        if depth is None:
            depth = sys.maxsize

        iter =self._generate_all([start], depth)

        if n:
            iter = itertools.islice(iter, n)

        return iter

    def _generate_all(self, items, depth):
        # see https://www.nltk.org/_modules/nltk/parse/generate.html
        if items:
            try:
                for frag1 in self._generate_one(items[0], depth):
                    for frag2 in self._generate_all(items[1:], depth):
                        yield frag1 + frag2
            except RuntimeError as _error:
                if _error.message == "maximum recursion depth exceeded":
                    # Helpful error message while still showing the recursion stack.
                    raise RuntimeError(
                        "The grammar has rule(s) that yield infinite recursion!!"
                    )
                else:
                    raise
        else:
            yield []

    def _generate_one(self, item, depth):
        # see https://www.nltk.org/_modules/nltk/parse/generate.html
        if depth > 0:
            if isinstance(item, Nonterminal):
                for prod in self.productions(lhs=item):
                    for frag in self._generate_all( prod.rhs(), depth - 1):
                        yield frag
            else:
                yield [item]

# helper function for quickly getting a single sample from multinomial with probs 
def choice(options,probs=None):
    x = np.random.rand()
    if probs==None:
        # then uniform probs
        num = len(options)
        probs = [1/num]*num
    cum = 0
    for i,p in enumerate(probs):
        cum += p
        if x < cum:
            break
    return options[i]


                
                
if __name__ == "__main__":
    # simple arithmetic grammar
    grammar = Grammar.fromstring("""
                 S -> S "+" T | S "*" T | S "/" T | T
                 T -> "(" S ")" | "sin(" S ")" | "exp(" S ")"
                 T -> "x" | "1" | "2" | "3"
                """)
    # sample a short sequences
    print(grammar.sampler(1,cfactor=0.0001))
    # print first sequences of depth 10
    print(grammar.generator(1,10))    
    # print the allowed productions
    print(grammar.productions())

    # SMILES grammar
    grammar = Grammar.fromstring("""
                 smiles -> chain
                 atom -> bracket_atom | aliphatic_organic | aromatic_organic
                 aliphatic_organic -> "B" | "C" | "N" | "O" | "S" | "P" | "F" | "I" | "Cl" | "Br"
                 aromatic_organic -> "c" | "n" | "o" | "s"
                 bracket_atom -> "[" BAI "]"
                 BAI -> isotope symbol BAC | symbol BAC | isotope symbol | symbol
                 BAC -> chiral BAH | BAH | chiral
                 BAH -> hcount BACH | BACH | hcount
                 BACH -> charge class | charge | class
                 symbol -> aliphatic_organic | aromatic_organic
                 isotope -> DIGIT | DIGIT DIGIT | DIGIT DIGIT DIGIT
                 class -> DIGIT | DIGIT DIGIT | DIGIT DIGIT DIGIT
                 DIGIT -> "1" | "2" | "3" | "4" | "5" | "6" | "7" | "8"
                 chiral -> "@" | "@@"
                 hcount -> "H" | "H" DIGIT
                 charge -> "−" | "−" DIGIT | "−" DIGIT DIGIT | "+" | "+" DIGIT | "+" DIGIT DIGIT
                 bond -> "−" | "=" | "#" | "/" | "\\"
                 ringbond -> DIGIT | bond DIGIT
                 branched_atom -> atom | atom RB | atom BB | atom RB BB
                 RB -> RB ringbond | ringbond
                 BB -> BB branch | branch
                 branch -> "(" chain ")" | "(" bond chain ")"
                 chain -> branched_atom | chain branched_atom | chain bond branched_atom
                """)
    # sample a short sequences
    print(grammar.sampler(1,cfactor=0.0001))
    # print first  sequences of depth 10
    print(grammar.generator(1,10))
    # print the allowed productions
    print(grammar.productions())
    
    
    